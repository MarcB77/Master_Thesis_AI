{"cells":[{"cell_type":"markdown","source":["### PAS OP. Indien deze notebook wordt gerund met overwrite tokenizer en NLP, dan krijgen woorden andere token values."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d50cb39-cc33-4422-9047-b49772f24513"}}},{"cell_type":"code","source":["%run /Users/pnl0rc8b@emea.royalahold.net/FINALIZED_Notebooks/Functions_Finalized"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0aef5dd-cf41-463b-b576-918a7d84687a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%run /Users/pnl0rc8b@emea.royalahold.net/FINALIZED_Notebooks/Functions_Tables"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f370bf4-adce-4f7b-a2b5-c669098782c9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#TO DO:\nDocumumenteren wat alle mogelijke input velden zijn. \nExtra parameter met naam dat je het bestand geeft tijdens opslaan"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da74674e-5521-4e70-9498-211ad363c472"}}},{"cell_type":"code","source":["NLP_nd = Natural_Language_Processing_nd(df_NLP, input_features=[\"regulatedProdName\",\"functionalName\",\"labelDescription\",\"TradeItemDescr\",\"ingredient_informatie\"], filename=\"NLP_file_1\")\ndf_preprocessed, tokenizer = NLP_nd.NLP_Loop(overwrite_tokenizer=True, overwrite_NLP_table=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6381dcfb-ed50-4c39-8e3b-d42fa5f562e8"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(df_preprocessed)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42f5b0cc-be35-4ccf-bea6-4486e5ea874b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# tokenizer_json = tokenizer.to_json()\n# dbutils.fs.put(\"/FileStore/nd_MODELS_publicatie/Tokenizer.json\", tokenizer_json)\n\n# test_text = tokenizer.texts_to_sequences([\"allergeen\",\"zien\"])\n# print(test_text)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d611b63f-1e5d-49e7-990f-f7baf035e9df"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"NLP_","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3338576279141099}},"nbformat":4,"nbformat_minor":0}
